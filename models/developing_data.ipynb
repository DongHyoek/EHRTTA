{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b8b255b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional, Dict, Tuple\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "static_vars = [\"age\", \"sex\", \"height\", \"weight\"]\n",
    "\n",
    "dynamic_vars = [\"alb\", \"alp\", \"alt\", \"ast\", \"be\", \"bicar\", \"bili\", \"bili_dir\",\n",
    "                  \"bnd\", \"bun\", \"ca\", \"cai\", \"ck\", \"ckmb\", \"cl\", \"crea\", \"crp\", \n",
    "                  \"dbp\", \"fgn\", \"fio2\", \"glu\", \"hgb\", \"hr\", \"inr_pt\", \"k\", \"lact\",\n",
    "                  \"lymph\", \"map\", \"mch\", \"mchc\", \"mcv\", \"methb\", \"mg\", \"na\", \"neut\", \n",
    "                  \"o2sat\", \"pco2\", \"ph\", \"phos\", \"plt\", \"po2\", \"ptt\", \"resp\", \"sbp\", \n",
    "                  \"temp\", \"tnt\", \"urine\", \"wbc\"]\n",
    "\n",
    "lab_vars = [\"alb\", \"alp\", \"alt\", \"ast\", \"be\", \"bicar\", \"bili\", \"bili_dir\",\n",
    "                  \"bnd\", \"bun\", \"ca\", \"cai\", \"ck\", \"ckmb\", \"cl\", \"crea\", \"crp\", \n",
    "                  \"fgn\", \"fio2\", \"glu\", \"hgb\", \"inr_pt\", \"k\", \"lact\",\n",
    "                  \"lymph\", \"mch\", \"mchc\", \"mcv\", \"methb\", \"mg\", \"na\", \"neut\", \n",
    "                  \"pco2\", \"ph\", \"phos\", \"plt\", \"po2\", \"ptt\", \"tnt\", \"wbc\"]\n",
    "\n",
    "vital_cols = [\"dbp\", \"sbp\", \"map\", \"hr\", \"o2sat\", \"resp\", \"temp\"]\n",
    "\n",
    "# Original Data Load..\n",
    "MIMIC_ROOT_DIR = Path('/Users/korea/EHRTTA/data/miiv')\n",
    "EICU_ROOT_DIR = Path('/Users/korea/EHRTTA/data/eicu')\n",
    "HIRID_ROOT_DIR = Path('/Users/korea/EHRTTA/data/hirid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d0db8f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hospitalid</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>stay_id</th>\n",
       "      <th>hospitaladmitoffset</th>\n",
       "      <th>hospitaldischargeoffset</th>\n",
       "      <th>unitdischargeoffset</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>unittype</th>\n",
       "      <th>hospitaladmitsource</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>admissionheight</th>\n",
       "      <th>admissionweight</th>\n",
       "      <th>hospitaldischargestatus</th>\n",
       "      <th>unitdischargestatus</th>\n",
       "      <th>los</th>\n",
       "      <th>mortality_inunit</th>\n",
       "      <th>los_reg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>002-10034</td>\n",
       "      <td>141169</td>\n",
       "      <td>157016</td>\n",
       "      <td>-3331</td>\n",
       "      <td>7503</td>\n",
       "      <td>4172</td>\n",
       "      <td>23</td>\n",
       "      <td>Female</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "      <td>Floor</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>162.6</td>\n",
       "      <td>63.5</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>2.897222</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>002-10050</td>\n",
       "      <td>183274</td>\n",
       "      <td>211144</td>\n",
       "      <td>-67</td>\n",
       "      <td>9764</td>\n",
       "      <td>5539</td>\n",
       "      <td>67</td>\n",
       "      <td>Female</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "      <td>Operating Room</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>160.0</td>\n",
       "      <td>86.2</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>3.846528</td>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>71</td>\n",
       "      <td>002-10050</td>\n",
       "      <td>190893</td>\n",
       "      <td>221005</td>\n",
       "      <td>-2140</td>\n",
       "      <td>9912</td>\n",
       "      <td>1897</td>\n",
       "      <td>68</td>\n",
       "      <td>Female</td>\n",
       "      <td>Med-Surg ICU</td>\n",
       "      <td>Floor</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>162.6</td>\n",
       "      <td>88.0</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>1.317361</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73</td>\n",
       "      <td>002-10052</td>\n",
       "      <td>137239</td>\n",
       "      <td>151900</td>\n",
       "      <td>-23</td>\n",
       "      <td>6378</td>\n",
       "      <td>3460</td>\n",
       "      <td>66</td>\n",
       "      <td>Female</td>\n",
       "      <td>MICU</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>165.1</td>\n",
       "      <td>86.8</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>2.402778</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>73</td>\n",
       "      <td>002-10063</td>\n",
       "      <td>189145</td>\n",
       "      <td>218742</td>\n",
       "      <td>-2</td>\n",
       "      <td>7804</td>\n",
       "      <td>5180</td>\n",
       "      <td>69</td>\n",
       "      <td>Female</td>\n",
       "      <td>Neuro ICU</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>152.4</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>3.597222</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78618</th>\n",
       "      <td>458</td>\n",
       "      <td>035-9957</td>\n",
       "      <td>2741786</td>\n",
       "      <td>3351785</td>\n",
       "      <td>-370</td>\n",
       "      <td>5343</td>\n",
       "      <td>2208</td>\n",
       "      <td>74</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cardiac ICU</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>182.9</td>\n",
       "      <td>75.7</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>1.533333</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78619</th>\n",
       "      <td>458</td>\n",
       "      <td>035-9959</td>\n",
       "      <td>2731423</td>\n",
       "      <td>3340321</td>\n",
       "      <td>0</td>\n",
       "      <td>3873</td>\n",
       "      <td>3873</td>\n",
       "      <td>44</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cardiac ICU</td>\n",
       "      <td>Direct Admit</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>185.4</td>\n",
       "      <td>130.6</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>2.689583</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78620</th>\n",
       "      <td>458</td>\n",
       "      <td>035-996</td>\n",
       "      <td>2736458</td>\n",
       "      <td>3345874</td>\n",
       "      <td>-73</td>\n",
       "      <td>11470</td>\n",
       "      <td>2761</td>\n",
       "      <td>55</td>\n",
       "      <td>Male</td>\n",
       "      <td>Cardiac ICU</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>African American</td>\n",
       "      <td>190.5</td>\n",
       "      <td>165.9</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>1.917361</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78621</th>\n",
       "      <td>458</td>\n",
       "      <td>035-9966</td>\n",
       "      <td>2742533</td>\n",
       "      <td>3352628</td>\n",
       "      <td>-261</td>\n",
       "      <td>3206</td>\n",
       "      <td>1872</td>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>MICU</td>\n",
       "      <td>Recovery Room</td>\n",
       "      <td>African American</td>\n",
       "      <td>170.1</td>\n",
       "      <td>120.2</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78622</th>\n",
       "      <td>458</td>\n",
       "      <td>035-9975</td>\n",
       "      <td>2731781</td>\n",
       "      <td>3340712</td>\n",
       "      <td>-342</td>\n",
       "      <td>11540</td>\n",
       "      <td>8117</td>\n",
       "      <td>69</td>\n",
       "      <td>Male</td>\n",
       "      <td>CTICU</td>\n",
       "      <td>Emergency Department</td>\n",
       "      <td>African American</td>\n",
       "      <td>185.4</td>\n",
       "      <td>95.0</td>\n",
       "      <td>Alive</td>\n",
       "      <td>Alive</td>\n",
       "      <td>5.636806</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78623 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hospitalid subject_id  hadm_id  stay_id  hospitaladmitoffset  \\\n",
       "0              63  002-10034   141169   157016                -3331   \n",
       "1              71  002-10050   183274   211144                  -67   \n",
       "2              71  002-10050   190893   221005                -2140   \n",
       "3              73  002-10052   137239   151900                  -23   \n",
       "4              73  002-10063   189145   218742                   -2   \n",
       "...           ...        ...      ...      ...                  ...   \n",
       "78618         458   035-9957  2741786  3351785                 -370   \n",
       "78619         458   035-9959  2731423  3340321                    0   \n",
       "78620         458    035-996  2736458  3345874                  -73   \n",
       "78621         458   035-9966  2742533  3352628                 -261   \n",
       "78622         458   035-9975  2731781  3340712                 -342   \n",
       "\n",
       "       hospitaldischargeoffset  unitdischargeoffset  age  gender  \\\n",
       "0                         7503                 4172   23  Female   \n",
       "1                         9764                 5539   67  Female   \n",
       "2                         9912                 1897   68  Female   \n",
       "3                         6378                 3460   66  Female   \n",
       "4                         7804                 5180   69  Female   \n",
       "...                        ...                  ...  ...     ...   \n",
       "78618                     5343                 2208   74    Male   \n",
       "78619                     3873                 3873   44    Male   \n",
       "78620                    11470                 2761   55    Male   \n",
       "78621                     3206                 1872   60    Male   \n",
       "78622                    11540                 8117   69    Male   \n",
       "\n",
       "           unittype   hospitaladmitsource         ethnicity  admissionheight  \\\n",
       "0      Med-Surg ICU                 Floor         Caucasian            162.6   \n",
       "1      Med-Surg ICU        Operating Room         Caucasian            160.0   \n",
       "2      Med-Surg ICU                 Floor         Caucasian            162.6   \n",
       "3              MICU  Emergency Department         Caucasian            165.1   \n",
       "4         Neuro ICU  Emergency Department         Caucasian            152.4   \n",
       "...             ...                   ...               ...              ...   \n",
       "78618   Cardiac ICU  Emergency Department         Caucasian            182.9   \n",
       "78619   Cardiac ICU          Direct Admit         Caucasian            185.4   \n",
       "78620   Cardiac ICU  Emergency Department  African American            190.5   \n",
       "78621          MICU         Recovery Room  African American            170.1   \n",
       "78622         CTICU  Emergency Department  African American            185.4   \n",
       "\n",
       "       admissionweight hospitaldischargestatus unitdischargestatus       los  \\\n",
       "0                 63.5                   Alive               Alive  2.897222   \n",
       "1                 86.2                   Alive               Alive  3.846528   \n",
       "2                 88.0                   Alive               Alive  1.317361   \n",
       "3                 86.8                   Alive               Alive  2.402778   \n",
       "4                 68.0                   Alive               Alive  3.597222   \n",
       "...                ...                     ...                 ...       ...   \n",
       "78618             75.7                   Alive               Alive  1.533333   \n",
       "78619            130.6                   Alive               Alive  2.689583   \n",
       "78620            165.9                   Alive               Alive  1.917361   \n",
       "78621            120.2                   Alive               Alive  1.300000   \n",
       "78622             95.0                   Alive               Alive  5.636806   \n",
       "\n",
       "       mortality_inunit  los_reg  \n",
       "0                     0       45  \n",
       "1                     0       68  \n",
       "2                     0        7  \n",
       "3                     0       33  \n",
       "4                     0       62  \n",
       "...                 ...      ...  \n",
       "78618                 0       12  \n",
       "78619                 0       40  \n",
       "78620                 0       22  \n",
       "78621                 0        7  \n",
       "78622                 0      111  \n",
       "\n",
       "[78623 rows x 19 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_df = pd.read_csv(EICU_ROOT_DIR/'outcome_df.csv.gz', compression='gzip')\n",
    "\n",
    "outcome_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "75632b80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stay_id</th>\n",
       "      <th>mortality_inunit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>157016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151900</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>218742</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78618</th>\n",
       "      <td>3351785</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78619</th>\n",
       "      <td>3340321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78620</th>\n",
       "      <td>3345874</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78621</th>\n",
       "      <td>3352628</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78622</th>\n",
       "      <td>3340712</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78623 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       stay_id  mortality_inunit\n",
       "0       157016                 0\n",
       "1       211144                 0\n",
       "2       221005                 0\n",
       "3       151900                 0\n",
       "4       218742                 0\n",
       "...        ...               ...\n",
       "78618  3351785                 0\n",
       "78619  3340321                 0\n",
       "78620  3345874                 0\n",
       "78621  3352628                 0\n",
       "78622  3340712                 0\n",
       "\n",
       "[78623 rows x 2 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_df[['stay_id', 'mortality_inunit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3424a080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======\\Users\\korea\\EHRTTA\\data\\miiv=======\n",
      "총 62638 명\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>var_name</th>\n",
       "      <th>dbp</th>\n",
       "      <th>hr</th>\n",
       "      <th>map</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>resp</th>\n",
       "      <th>sbp</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>62297.000000</td>\n",
       "      <td>62563.000000</td>\n",
       "      <td>62544.000000</td>\n",
       "      <td>62593.000000</td>\n",
       "      <td>62467.000000</td>\n",
       "      <td>62300.000000</td>\n",
       "      <td>60728.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.371077</td>\n",
       "      <td>28.176254</td>\n",
       "      <td>27.993988</td>\n",
       "      <td>29.737654</td>\n",
       "      <td>28.525237</td>\n",
       "      <td>27.377448</td>\n",
       "      <td>8.256784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.072069</td>\n",
       "      <td>8.180203</td>\n",
       "      <td>8.926030</td>\n",
       "      <td>8.367161</td>\n",
       "      <td>8.792303</td>\n",
       "      <td>9.074107</td>\n",
       "      <td>5.434505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>308.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>309.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>688.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>118.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "var_name           dbp            hr           map         o2sat  \\\n",
       "count     62297.000000  62563.000000  62544.000000  62593.000000   \n",
       "mean         27.371077     28.176254     27.993988     29.737654   \n",
       "std           9.072069      8.180203      8.926030      8.367161   \n",
       "min           1.000000      1.000000      1.000000      1.000000   \n",
       "25%          24.000000     24.000000     24.000000     26.000000   \n",
       "50%          25.000000     26.000000     25.000000     28.000000   \n",
       "75%          30.000000     30.000000     30.000000     32.000000   \n",
       "max         308.000000    313.000000    309.000000    324.000000   \n",
       "\n",
       "var_name          resp           sbp          temp  \n",
       "count     62467.000000  62300.000000  60728.000000  \n",
       "mean         28.525237     27.377448      8.256784  \n",
       "std           8.792303      9.074107      5.434505  \n",
       "min           1.000000      1.000000      1.000000  \n",
       "25%          25.000000     24.000000      6.000000  \n",
       "50%          26.000000     25.000000      7.000000  \n",
       "75%          30.000000     30.000000      8.000000  \n",
       "max         688.000000    308.000000    118.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "var_name\n",
       "dbp       296\n",
       "hr         30\n",
       "map        49\n",
       "o2sat       0\n",
       "resp      126\n",
       "sbp       293\n",
       "temp     1865\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\korea\\AppData\\Local\\Temp\\ipykernel_13912\\1715452613.py:4: DtypeWarning: Columns (2) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  static_df = pd.read_csv(dir/'static_df.csv.gz', compression='gzip')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======\\Users\\korea\\EHRTTA\\data\\eicu=======\n",
      "총 78623 명\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>var_name</th>\n",
       "      <th>dbp</th>\n",
       "      <th>hr</th>\n",
       "      <th>map</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>resp</th>\n",
       "      <th>sbp</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20545.000000</td>\n",
       "      <td>77322.000000</td>\n",
       "      <td>77285.000000</td>\n",
       "      <td>76927.000000</td>\n",
       "      <td>70776.000000</td>\n",
       "      <td>20558.000000</td>\n",
       "      <td>8842.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>218.195814</td>\n",
       "      <td>273.854543</td>\n",
       "      <td>109.133079</td>\n",
       "      <td>254.599126</td>\n",
       "      <td>263.968973</td>\n",
       "      <td>218.246376</td>\n",
       "      <td>216.750622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>79.088619</td>\n",
       "      <td>28.337627</td>\n",
       "      <td>106.450391</td>\n",
       "      <td>54.606222</td>\n",
       "      <td>45.927062</td>\n",
       "      <td>79.176983</td>\n",
       "      <td>78.954987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>181.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>181.000000</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>251.000000</td>\n",
       "      <td>284.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>251.000000</td>\n",
       "      <td>246.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>281.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>286.000000</td>\n",
       "      <td>287.000000</td>\n",
       "      <td>282.000000</td>\n",
       "      <td>280.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>289.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>1614.000000</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>289.000000</td>\n",
       "      <td>289.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "var_name           dbp            hr           map         o2sat  \\\n",
       "count     20545.000000  77322.000000  77285.000000  76927.000000   \n",
       "mean        218.195814    273.854543    109.133079    254.599126   \n",
       "std          79.088619     28.337627    106.450391     54.606222   \n",
       "min           1.000000      1.000000      1.000000      1.000000   \n",
       "25%         181.000000    273.000000     35.000000    250.000000   \n",
       "50%         251.000000    284.000000     63.000000    276.000000   \n",
       "75%         281.000000    287.000000    139.000000    286.000000   \n",
       "max         289.000000    289.000000   1614.000000    308.000000   \n",
       "\n",
       "var_name          resp           sbp         temp  \n",
       "count     70776.000000  20558.000000  8842.000000  \n",
       "mean        263.968973    218.246376   216.750622  \n",
       "std          45.927062     79.176983    78.954987  \n",
       "min           1.000000      1.000000     1.000000  \n",
       "25%         264.000000    181.000000   180.000000  \n",
       "50%         281.000000    251.000000   246.000000  \n",
       "75%         287.000000    282.000000   280.000000  \n",
       "max         289.000000    289.000000   289.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "var_name\n",
       "dbp      57068\n",
       "hr         291\n",
       "map        328\n",
       "o2sat      686\n",
       "resp      6837\n",
       "sbp      57055\n",
       "temp     68771\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=======\\Users\\korea\\EHRTTA\\data\\hirid=======\n",
      "총 13109 명\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>var_name</th>\n",
       "      <th>dbp</th>\n",
       "      <th>hr</th>\n",
       "      <th>map</th>\n",
       "      <th>o2sat</th>\n",
       "      <th>resp</th>\n",
       "      <th>sbp</th>\n",
       "      <th>temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12760.000000</td>\n",
       "      <td>13048.000000</td>\n",
       "      <td>13047.000000</td>\n",
       "      <td>13054.000000</td>\n",
       "      <td>13041.000000</td>\n",
       "      <td>12760.000000</td>\n",
       "      <td>7825.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>708.626019</td>\n",
       "      <td>750.200874</td>\n",
       "      <td>700.468767</td>\n",
       "      <td>725.577448</td>\n",
       "      <td>564.045472</td>\n",
       "      <td>710.264577</td>\n",
       "      <td>183.852396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>223.529453</td>\n",
       "      <td>217.444321</td>\n",
       "      <td>237.772883</td>\n",
       "      <td>210.051193</td>\n",
       "      <td>496.798978</td>\n",
       "      <td>223.628975</td>\n",
       "      <td>260.204839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>643.000000</td>\n",
       "      <td>677.000000</td>\n",
       "      <td>641.000000</td>\n",
       "      <td>646.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>645.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>699.000000</td>\n",
       "      <td>715.000000</td>\n",
       "      <td>702.000000</td>\n",
       "      <td>698.000000</td>\n",
       "      <td>553.000000</td>\n",
       "      <td>701.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>717.000000</td>\n",
       "      <td>722.000000</td>\n",
       "      <td>719.000000</td>\n",
       "      <td>721.000000</td>\n",
       "      <td>973.000000</td>\n",
       "      <td>719.000000</td>\n",
       "      <td>425.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1958.000000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>1963.000000</td>\n",
       "      <td>1955.000000</td>\n",
       "      <td>1492.000000</td>\n",
       "      <td>1962.000000</td>\n",
       "      <td>753.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "var_name           dbp            hr           map         o2sat  \\\n",
       "count     12760.000000  13048.000000  13047.000000  13054.000000   \n",
       "mean        708.626019    750.200874    700.468767    725.577448   \n",
       "std         223.529453    217.444321    237.772883    210.051193   \n",
       "min           1.000000      1.000000      5.000000      1.000000   \n",
       "25%         643.000000    677.000000    641.000000    646.000000   \n",
       "50%         699.000000    715.000000    702.000000    698.000000   \n",
       "75%         717.000000    722.000000    719.000000    721.000000   \n",
       "max        1958.000000   1965.000000   1963.000000   1955.000000   \n",
       "\n",
       "var_name          resp           sbp         temp  \n",
       "count     13041.000000  12760.000000  7825.000000  \n",
       "mean        564.045472    710.264577   183.852396  \n",
       "std         496.798978    223.628975   260.204839  \n",
       "min           1.000000      1.000000     1.000000  \n",
       "25%          17.000000    645.000000     5.000000  \n",
       "50%         553.000000    701.000000    10.000000  \n",
       "75%         973.000000    719.000000   425.000000  \n",
       "max        1492.000000   1962.000000   753.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "var_name\n",
       "dbp       297\n",
       "hr          9\n",
       "map        10\n",
       "o2sat       3\n",
       "resp       16\n",
       "sbp       297\n",
       "temp     5232\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dir in [MIMIC_ROOT_DIR, EICU_ROOT_DIR, HIRID_ROOT_DIR]:\n",
    "    # Data Load\n",
    "    dynamics_df = pd.read_csv(dir/'dynamics_df.csv.gz', compression='gzip')\n",
    "    static_df = pd.read_csv(dir/'static_df.csv.gz', compression='gzip')\n",
    "\n",
    "    \n",
    "    mapping = {'anchor_age' : 'age', 'gender' : 'sex'}\n",
    "    static_df['var_name'] = static_df['var_name'].replace(mapping)\n",
    "\n",
    "    with open('/Users/korea/EHRTTA/data/concept-dict.json', 'r') as f:\n",
    "        concept_dict = json.load(f)\n",
    "\n",
    "    print(f'======={dir}=======')\n",
    "    print(f'총 {static_df.stay_id.nunique()} 명')\n",
    "    \n",
    "    observed_ts_df = dynamics_df[dynamics_df['var_name'].isin(vital_cols)].groupby(['stay_id', 'var_name'],as_index=False).count()\n",
    "    display(observed_ts_df.pivot(columns='var_name', index='stay_id', values='value').describe())\n",
    "    display(observed_ts_df.pivot(columns='var_name', index='stay_id', values='value').isna().sum())\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "202995e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/korea/EHRTTA/data'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    data_path = '/Users/korea/EHRTTA/data'\n",
    "    var_info_path = '/Users/korea/EHRTTA/data/concept-dict.json'\n",
    "    data_source = 'miiv'\n",
    "    task_label = 'mortality_inunit'\n",
    "    pid_col = 'stay_id'\n",
    "    offset_col = 'charttime'\n",
    "\n",
    "args = Config\n",
    "\n",
    "args.data_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6043df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class ISTS_EHR_Dataset(Dataset):\n",
    "    def __init__(self, args):\n",
    "\n",
    "        super(ISTS_EHR_Dataset, self).__init__()\n",
    "        \n",
    "        self.args = args\n",
    "        self.data_source = args.data_source\n",
    "        self.task_label = args.task_label\n",
    "        self.pid = args.pid_col\n",
    "        self.offset = args.offset_col\n",
    "\n",
    "        # Set the variable groups\n",
    "        self.dg_cols = [\"age\", \"sex\", \"height\", \"weight\"] \n",
    "        self.ts_cols = [\"dbp\", \"sbp\", \"map\", \"hr\", \"o2sat\", \"resp\", \"temp\"]\n",
    "        self.lab_cols = [\"alb\", \"alp\", \"alt\", \"ast\", \"be\", \"bicar\", \"bili\", \"bili_dir\",\"bnd\", \"bun\", \"ca\", \"cai\", \n",
    "                         \"ck\", \"ckmb\", \"cl\", \"crea\", \"crp\", \"fgn\", \"fio2\", \"glu\", \"hgb\", \"inr_pt\", \"k\", \"lact\",\n",
    "                         \"lymph\", \"mch\", \"mchc\", \"mcv\", \"methb\", \"mg\", \"na\", \"neut\", \"pco2\", \"ph\", \"phos\", \"plt\", \n",
    "                         \"po2\", \"ptt\", \"tnt\", \"wbc\"]\n",
    "        self.output_cols = [\"urine\"]\n",
    "        \n",
    "        # load dataframe\n",
    "        dynamics_df = pd.read_csv(Path(args.data_path)/args.data_source/'dynamics_df.csv.gz', compression='gzip')\n",
    "        \n",
    "        self.static_df = pd.read_csv(Path(args.data_path)/args.data_source/'static_df.csv.gz', compression='gzip')\n",
    "        self.outcome_df = pd.read_csv(Path(args.data_path)/args.data_source/'outcome_df.csv.gz', compression='gzip')\n",
    "        self.ts_df = dynamics_df[dynamics_df['var_name'].isin(self.ts_cols)]\n",
    "        self.text_df = dynamics_df[dynamics_df['var_name'].isin([self.lab_cols + self.output_cols])]\n",
    "\n",
    "        del dynamics_df\n",
    "        \n",
    "        y_data = self.outcome_df.sort_values(self.pid)[self.task_label].reset_index(drop=True)\n",
    "        \n",
    "        display(y_data)\n",
    "\n",
    "        self.X_ts_data = torch.from_numpy(self.reshape_data_matrix()).float() # (N, T, C)\n",
    "        # self.X_text_data =  \n",
    "        self.y_data = torch.from_numpy(y_data).long()  # (N)\n",
    "\n",
    "        print(f'Input X, Y Shape : {self.X_data.shape}, {self.y_data.shape}')\n",
    "        print(f'Unique values of the label: {np.unique(y_data)}')\n",
    "        \n",
    "        # For univariate time series\n",
    "        if len(self.X_data.shape) < 3:\n",
    "            self.X_data = self.X_data.unsqueeze(2)\n",
    "\n",
    "        self.len = self.X_data.shape[0]\n",
    "\n",
    "    def reshape_data_matrix(self):\n",
    "\n",
    "        df = self.ts_df.sort_values([self.pid, self.offset]).reset_index(drop=True)\n",
    "        \n",
    "        grouped_df = df.groupby([self.pid, self.offset])[self.ts_cols].mean() # Use raw value at each time seqeunce.\n",
    "        result = grouped_df.values.reshape(self.static_df[self.pid].nunique(), self.args.seq_len, len(self.ts_cols))\n",
    "                \n",
    "        return result\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.X_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "\n",
    "ISTS_EHR_Dataset(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4fe7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_data_matrix(self):\n",
    "\n",
    "    df = self.ts_df.sort_values([self.pid, self.offset]).reset_index(drop=True)\n",
    "    \n",
    "    grouped_df = df.groupby([self.pid, self.offset]).mean() # Use raw value at each time seqeunce. \n",
    "    result = grouped_df.values.reshape(self.df[self.pid].nunique(), self.args.seq_len, len(self.ts_cols))\n",
    "            \n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9190ea6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dynamics_df[dynamics_df['var_name'].isin(vital_cols)].reset_index(drop=True)\n",
    "\n",
    "grouped_df = df.groupby(['stay_id', 'charttime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9df26ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stay_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>var_name</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>resp</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>temp</td>\n",
       "      <td>36.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>hr</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>o2sat</td>\n",
       "      <td>94.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>hr</td>\n",
       "      <td>59.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55298726</th>\n",
       "      <td>33904</td>\n",
       "      <td>1439</td>\n",
       "      <td>map</td>\n",
       "      <td>66.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55298727</th>\n",
       "      <td>33904</td>\n",
       "      <td>1439</td>\n",
       "      <td>sbp</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55298728</th>\n",
       "      <td>33904</td>\n",
       "      <td>1440</td>\n",
       "      <td>hr</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55298729</th>\n",
       "      <td>33904</td>\n",
       "      <td>1440</td>\n",
       "      <td>resp</td>\n",
       "      <td>23.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55298730</th>\n",
       "      <td>33904</td>\n",
       "      <td>1440</td>\n",
       "      <td>resp</td>\n",
       "      <td>23.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55298731 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          stay_id  charttime var_name      value\n",
       "0               2          5     resp  25.000000\n",
       "1               2          5     temp  36.799999\n",
       "2               2         17       hr  55.000000\n",
       "3               2         17    o2sat  94.000000\n",
       "4               2         18       hr  59.000000\n",
       "...           ...        ...      ...        ...\n",
       "55298726    33904       1439      map  66.000000\n",
       "55298727    33904       1439      sbp  91.000000\n",
       "55298728    33904       1440       hr  85.000000\n",
       "55298729    33904       1440     resp  23.900000\n",
       "55298730    33904       1440     resp  23.900000\n",
       "\n",
       "[55298731 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4986fc75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['age', 'sex', 'height', 'weight'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "static_df.var_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34a8ef56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# 해당 데이터셋마다 필요한 값들을 excel 형식으로 변환해보자.\n",
    "\n",
    "def select_vars(db_name, var_list, base_dict):\n",
    "    \"\"\"\n",
    "    min, max => 이상치 처리 시 사용\n",
    "    cateogries => 해당 변수 category 분류 시 사용\n",
    "    source_table => 어느 테이블에서 가져와야 하는지\n",
    "    source_columns => 해당 테이블 어느 컬럼에서 가져와야 하는지\n",
    "    source_itemid => 해당 테이블의 컬럼에서 어떤 id로 존재하는지\n",
    "    \"\"\"\n",
    "    var_normal_min = []\n",
    "    var_normal_max = []\n",
    "    var_unit = []\n",
    "    source_category = []\n",
    "    source_table = []\n",
    "    source_column = []\n",
    "    source_itemid = []\n",
    "    source_callback = []\n",
    "    source_vars = [] # to map other lists\n",
    "    for var in tqdm(var_list):\n",
    "\n",
    "        for i in range(len(base_dict[var]['sources'][db_name])): # 여러 테이블에 분산되어 있는 경우 길이가 2가 넘을 수 있기 때문\n",
    "\n",
    "            source_table.append(base_dict[var]['sources'][db_name][i]['table'])\n",
    "\n",
    "            try:\n",
    "                source_column.append(base_dict[var]['sources'][db_name][i]['sub_var'])\n",
    "            except:\n",
    "                source_column.append(base_dict[var]['sources'][db_name][i]['val_var'])\n",
    "\n",
    "            try:\n",
    "                if [223761, 224027] == base_dict[var]['sources'][db_name][i]['ids']: # temp 관련 변수에서 skin temp는 제외 \n",
    "                    source_itemid.append(223761)\n",
    "                \n",
    "                else:\n",
    "                    source_itemid.append(base_dict[var]['sources'][db_name][i]['ids'])\n",
    "            except:\n",
    "                source_itemid.append(None)\n",
    "\n",
    "            try:\n",
    "                source_callback.append(base_dict[var]['sources'][db_name][i]['callback'])\n",
    "            except:\n",
    "                source_callback.append(None)\n",
    "\n",
    "\n",
    "            source_category.append(base_dict[var]['category'])\n",
    "\n",
    "            try:\n",
    "                var_unit.append(base_dict[var]['unit'])\n",
    "            except:\n",
    "                var_unit.append(None)\n",
    "\n",
    "            try:\n",
    "                var_normal_min.append(base_dict[var]['min'])\n",
    "            except:\n",
    "                var_normal_min.append(None)\n",
    "            \n",
    "            try:\n",
    "                var_normal_max.append(base_dict[var]['max'])\n",
    "            except:\n",
    "                var_normal_max.append(None)\n",
    "\n",
    "            source_vars.append(var)\n",
    "        \n",
    "    return var_normal_min, var_normal_max, var_unit, source_category, source_table, source_column, source_itemid, source_callback, source_vars\n",
    "\n",
    "var_normal_min, var_normal_max, var_unit, source_category, source_table, source_column, source_itemid, source_callback, source_vars  = select_vars('miiv', static_vars + dynamic_vars, concept_dict)\n",
    "\n",
    "MAPPING_DF = pd.DataFrame({\n",
    "    'var_name' : source_vars,\n",
    "    'normal_min' : var_normal_min,\n",
    "    'normal_max' : var_normal_max,\n",
    "    'category' : source_category,\n",
    "    'table' : source_table,\n",
    "    'column' : source_column,\n",
    "    'itemid' : source_itemid,\n",
    "    'unit' : var_unit,\n",
    "    'method' : source_callback \n",
    "})\n",
    "\n",
    "# FUll name 및 추가 \n",
    "full_name_dict = {'age' : 'Age', 'sex' : 'Sex', 'height' : 'Height', 'weight' : 'Weight', 'sbp' : 'Blood pressure (systolic)', 'dbp' : 'Blood pressure (diastolic)', 'hr' : 'Heart rate', 'map' : 'Mean arterial pressure', 'o2sat' : 'Oxygen saturation',\n",
    "                  'resp' : 'Respiratory rate', 'temp' : 'Temperature', 'alb' : 'Albumin', 'alp' : 'Alkaline phosphatase', 'alt' : 'Alanine aminotransferase', 'ast' : 'Aspartate aminotransferase', 'be' : 'Base excess', 'bicar' : 'Bicarbonate',\n",
    "                  'bili' : 'Bilirubin (total)', 'bili_dir' : 'Bilirubin (direct)', 'bnd' : 'Band form neutrophils', 'bun' : 'Blood urea nitrogen', 'ca' : 'Calcium', 'cai' : 'Calcium ionized', 'crea' : 'Creatinine', 'ck' : 'Creatinine kinase',\n",
    "                  'ckmb' : 'Creatinine kinase MB', 'cl' : 'Chloride', 'pco2' : 'CO2 partial pressure', 'crp' : 'C-reactive protein', 'fgn' : 'Fibrinogen', 'glu' : 'Glucose', 'hgb' : 'Haemoglobin', 'inr_pt' : 'International normalised ratio (INR)',\n",
    "                  'lact' : 'Lactate', 'lymph' : 'Lymphocytes', 'mch' : 'Mean cell haemoglobin', 'mchc' : 'Mean corpuscular haemoglobin concentration', 'mcv' : 'Mean corpuscular volume', 'methb' : 'Methaemoglobin', 'mg' : 'Magnesium', \n",
    "                  'neut' : 'Neutrophils', 'po2' : 'O2 partial pressure', 'ptt' : 'Partial thromboplastin time', 'ph' : 'pH of blood', 'phos' : 'Phosphate', 'plt' : 'Platelets', 'k' : 'Potassium', 'na' : 'Sodium', 'tnt' : 'Troponin T', \n",
    "                  'wbc' : 'White blood cells', 'fio2' : 'Fraction of inspired oxygen', 'urine' : 'Urine output'\n",
    "                  }\n",
    "\n",
    "fixed_unit_dict = {'age' : 'Years', 'sex' : '', 'height' : 'cm', 'weight' : 'kg', 'sbp' : 'mmHg', 'dbp' : 'mmHg', 'hr' : 'beats/minute', 'map' : 'mmHg', 'o2sat' : '%',\n",
    "                  'resp' : 'breaths/minute', 'temp' : '°C', 'alb' : 'g/dL', 'alp' : 'IU/L', 'alt' : 'IU/L', 'ast' : 'IU/L', 'be' : 'mmol/L', 'bicar' : 'mmol/L',\n",
    "                  'bili' : 'mg/dL', 'bili_dir' : 'mg/dL', 'bnd' : '%', 'bun' : 'mg/dL', 'ca' : 'mg/dL', 'cai' : 'mmol/L', 'crea' : 'mg/dL', 'ck' : 'IU/L',\n",
    "                  'ckmb' : 'ng/mL', 'cl' : 'mmol/L', 'pco2' : 'mmHg', 'crp' : 'mg/L', 'fgn' : 'mg/dL', 'glu' : 'mg/dL', 'hgb' : 'g/dL', 'inr_pt' : '',\n",
    "                  'lact' : 'mmol/L', 'lymph' : '%', 'mch' : 'pg', 'mchc' : '%', 'mcv' : 'fL', 'methb' : '%', 'mg' : 'mg/dL', \n",
    "                  'neut' : '%', 'po2' : 'mmHg', 'ptt' : 'sec', 'ph' : '', 'phos' : 'mg/dL', 'plt' : '1,000 / μL', 'k' : 'mmol/L', 'na' : 'mmol/L', 'tnt' : 'ng/mL', \n",
    "                  'wbc' : '1,000 / μL', 'fio2' : '%', 'urine' : 'mL'\n",
    "                  }\n",
    "\n",
    "MAPPING_DF['full_var_name'] = MAPPING_DF['var_name'].apply(lambda x : full_name_dict[x])\n",
    "MAPPING_DF['fixed_unit'] = MAPPING_DF['var_name'].apply(lambda x : fixed_unit_dict[x])\n",
    "MAPPING_DF = MAPPING_DF[['var_name', 'normal_min', 'normal_max', 'full_var_name', 'fixed_unit']] # only using variables\n",
    "MAPPING_DF = MAPPING_DF.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "407c00c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "# lab vars 변경\n",
    "lab_vars = [full_name_dict[i] for i in lab_vars]\n",
    "print(len(lab_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc721ee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Albumin',\n",
       " 'Alkaline phosphatase',\n",
       " 'Alanine aminotransferase',\n",
       " 'Aspartate aminotransferase',\n",
       " 'Base excess',\n",
       " 'Bicarbonate',\n",
       " 'Bilirubin (total)',\n",
       " 'Bilirubin (direct)',\n",
       " 'Band form neutrophils',\n",
       " 'Blood urea nitrogen',\n",
       " 'Calcium',\n",
       " 'Calcium ionized',\n",
       " 'Creatinine kinase',\n",
       " 'Creatinine kinase MB',\n",
       " 'Chloride',\n",
       " 'Creatinine',\n",
       " 'C-reactive protein',\n",
       " 'Fibrinogen',\n",
       " 'Fraction of inspired oxygen',\n",
       " 'Glucose',\n",
       " 'Haemoglobin',\n",
       " 'International normalised ratio (INR)',\n",
       " 'Potassium',\n",
       " 'Lactate',\n",
       " 'Lymphocytes',\n",
       " 'Mean cell haemoglobin',\n",
       " 'Mean corpuscular haemoglobin concentration',\n",
       " 'Mean corpuscular volume',\n",
       " 'Methaemoglobin',\n",
       " 'Magnesium',\n",
       " 'Sodium',\n",
       " 'Neutrophils',\n",
       " 'CO2 partial pressure',\n",
       " 'pH of blood',\n",
       " 'Phosphate',\n",
       " 'Platelets',\n",
       " 'O2 partial pressure',\n",
       " 'Partial thromboplastin time',\n",
       " 'Troponin T',\n",
       " 'White blood cells']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1248e8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13109/13109 [16:41<00:00, 13.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, Optional, Tuple, Set, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Config\n",
    "# ============================================================\n",
    "@dataclass\n",
    "class MarkdownSummaryConfig:\n",
    "    # --- Input dataframe column names ---\n",
    "    # charttime is already \"minutes since admission\" (int)\n",
    "    time_col: str = \"charttime\"     # minutes since ICU admission (int)\n",
    "    id_col: str = \"stay_id\"\n",
    "    var_col: str = \"full_var_name\"\n",
    "    val_col: str = \"value\"\n",
    "    unit_col: str = \"fixed_unit\"\n",
    "    normal_min : str = 'normal_min'\n",
    "    normal_max : str = 'normal_max'\n",
    "    \n",
    "    # --- Feature definitions ---\n",
    "    # slope = (Δvalue) / (Δminutes)\n",
    "    # variability = abs(Δvalue) by default\n",
    "    variability_mode: str = \"abs_delta\"  # \"abs_delta\" or \"rolling_std\"\n",
    "    rolling_window: int = 5              # used when variability_mode == \"rolling_std\"\n",
    "    min_points_for_stats: int = 2        # rolling/std 최소 관측 수\n",
    "\n",
    "    # --- Formatting ---\n",
    "    round_ndigits: int = 1\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Formatting helpers\n",
    "# ============================================================\n",
    "def fmt_number(x: Any, ndigits: int = 1, type='measurement') -> str:\n",
    "    \"\"\"Format numbers; use 'Not observed' for None/NaN.\"\"\"\n",
    "    \n",
    "    if x is None and type == 'measurement':\n",
    "        return \"Not observed\"\n",
    "    \n",
    "    if pd.isna(x) and type == 'normal_max':\n",
    "        return \"inf\"\n",
    "    \n",
    "    if pd.isna(x) and type == 'normal_min':\n",
    "        return \"-inf\"\n",
    "\n",
    "    try:\n",
    "        if isinstance(x, float) and np.isnan(x):\n",
    "            return \"Not observed\"\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    if isinstance(x, (int, np.integer)):\n",
    "        return str(int(x))\n",
    "\n",
    "    try:\n",
    "        return f\"{float(x):.{ndigits}f}\"\n",
    "    except Exception:\n",
    "        return \"Not observed\"\n",
    "\n",
    "\n",
    "def nan_stats(x: np.ndarray) -> Dict[str, Optional[float]]:\n",
    "    \"\"\"Return min/max/mean/std on numeric array, ignoring NaNs.\"\"\"\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    x = x[~np.isnan(x)]\n",
    "    if x.size == 0:\n",
    "        return {\"min\": None, \"max\": None, 'median' : None ,\"mean\": None, \"std\": None}\n",
    "\n",
    "    std = float(np.std(x, ddof=1)) if x.size > 1 else 0.0\n",
    "    return {\n",
    "        \"min\": float(np.min(x)),\n",
    "        \"max\": float(np.max(x)),\n",
    "        'median' : float(np.median(x)),\n",
    "        \"mean\": float(np.mean(x)),\n",
    "        \"std\": std,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Feature computation (per variable)\n",
    "# ============================================================\n",
    "def compute_variable_features(\n",
    "    var_df: pd.DataFrame,\n",
    "    cfg: MarkdownSummaryConfig,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Compute summary features for ONE variable group.\n",
    "    Assumption: cfg.time_col is already minutes (int) since admission.\n",
    "    \"\"\"\n",
    "    df_sorted = var_df.sort_values(cfg.time_col).copy()\n",
    "\n",
    "    times_min = pd.to_numeric(df_sorted[cfg.time_col], errors=\"coerce\").to_numpy(dtype=float)\n",
    "    values = pd.to_numeric(df_sorted[cfg.val_col], errors=\"coerce\").to_numpy(dtype=float)\n",
    "\n",
    "    # observation count (non-NaN values)\n",
    "    n_obs = int(np.sum(~np.isnan(values)))\n",
    "\n",
    "    # first/last time (minutes)\n",
    "    first_min = float(times_min[0]) if times_min.size else None\n",
    "    last_min = float(times_min[-1]) if times_min.size else None\n",
    "\n",
    "    # interval mean (unique time 기준)\n",
    "    unique_times = np.unique(times_min[~np.isnan(times_min)])\n",
    "    if unique_times.size >= 2:\n",
    "        interval_mean_min = float(np.mean(np.diff(unique_times)))\n",
    "    else:\n",
    "        interval_mean_min = None\n",
    "\n",
    "    # value stats\n",
    "    value_stats = nan_stats(values)\n",
    "\n",
    "    # slope stats: Δy / Δt (dt>0)\n",
    "    slopes = np.array([], dtype=float)\n",
    "    if times_min.size >= 2:\n",
    "        dt = np.diff(times_min)\n",
    "        dy = np.diff(values)\n",
    "        mask = (~np.isnan(dt)) & (~np.isnan(dy)) & (dt > 0)\n",
    "        if np.any(mask):\n",
    "            slopes = dy[mask] / dt[mask]\n",
    "    slope_stats = nan_stats(slopes) if slopes.size else {\"min\": None, \"max\": None, \"mean\": None, \"std\": None}\n",
    "\n",
    "    # variability stats\n",
    "    if cfg.variability_mode == \"abs_delta\":\n",
    "        variability_seq = np.abs(np.diff(values))\n",
    "        variability_seq = variability_seq[~np.isnan(variability_seq)]\n",
    "    elif cfg.variability_mode == \"rolling_std\":\n",
    "        rolling_std = (\n",
    "            pd.Series(values)\n",
    "            .rolling(cfg.rolling_window, min_periods=cfg.min_points_for_stats)\n",
    "            .std()\n",
    "            .to_numpy(dtype=float)\n",
    "        )\n",
    "        variability_seq = rolling_std[~np.isnan(rolling_std)]\n",
    "    else:\n",
    "        raise ValueError(\"variability_mode must be 'abs_delta' or 'rolling_std'\")\n",
    "\n",
    "    variability_stats = nan_stats(variability_seq) if variability_seq.size else {\"min\": None, \"max\": None, \"mean\": None, \"std\": None}\n",
    "\n",
    "    return {\n",
    "        \"first_min\": first_min,\n",
    "        \"last_min\": last_min,\n",
    "        \"n_obs\": n_obs,\n",
    "        \"interval_mean_min\": interval_mean_min,\n",
    "        \"value_stats\": value_stats,\n",
    "        \"slope_stats\": slope_stats,\n",
    "        \"variability_stats\": variability_stats,\n",
    "    }\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Markdown builder (per patient)\n",
    "# ============================================================\n",
    "def build_patient_markdown_summary(\n",
    "    observations: pd.DataFrame,\n",
    "    demographics: pd.DataFrame,\n",
    "    mapping_df : pd.DataFrame,\n",
    "    cfg: Optional[MarkdownSummaryConfig] = None,\n",
    "    labs_title: str = \"Summary of Lab Results\",\n",
    "    lab_var_list: Optional[list[str]] = None,\n",
    "    output_var_names: Optional[Set[str]] = ['Urine output'],\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    observations: one patient's observation rows\n",
    "      - must include: cfg.time_col (minutes), cfg.var_col, cfg.val_col\n",
    "    demographics: {\"Age\":..., \"Gender\":..., \"Weight\":..., \"Height\":...}\n",
    "    normal_ranges: {\"WBC\": (4,11), ...}\n",
    "    output_var_names: variables to treat as \"Output Events\" section\n",
    "    \"\"\"\n",
    "    cfg = cfg or MarkdownSummaryConfig()\n",
    "    output_var_names = output_var_names or set()\n",
    "\n",
    "    df = observations.copy()\n",
    "    df[cfg.val_col] = pd.to_numeric(df[cfg.val_col], errors=\"coerce\")\n",
    "    df[cfg.time_col] = pd.to_numeric(df[cfg.time_col], errors=\"coerce\")  # ensure numeric minutes\n",
    "\n",
    "    # ----------------------------\n",
    "    # Header: demographics\n",
    "    # ----------------------------\n",
    "    md_lines = []\n",
    "    md_lines.append(\"# Patient Demographics at ICU Admission\\n\")\n",
    "    md_lines.append(f\"- Age : {fmt_number(demographics[demographics['full_var_name'] == 'Age']['value'].values[0])}\")\n",
    "    md_lines.append(f\"- Gender : {demographics[demographics['full_var_name'] == 'Sex']['value'].values[0]}\")\n",
    "\n",
    "    try:\n",
    "        md_lines.append(f\"- Weight : {fmt_number(demographics[demographics['full_var_name'] == 'Weight']['value'].values[0])}kg\")\n",
    "    except:\n",
    "        md_lines.append(f\"- Weight : Not observed\")\n",
    "    \n",
    "    try:\n",
    "        md_lines.append(f\"- Height : {fmt_number(demographics[demographics['full_var_name'] == 'Height']['value'].values[0])}cm \\n\")\n",
    "    except:\n",
    "        md_lines.append(f\"- Height : Not observed\")\n",
    "\n",
    "    md_lines.append(\"\")\n",
    "\n",
    "    # ----------------------------\n",
    "    # Split labs vs outputs\n",
    "    # ----------------------------\n",
    "    is_output = df[cfg.var_col].isin(output_var_names)\n",
    "    labs_df = df[~is_output].copy()\n",
    "    output_df = df[is_output].copy()\n",
    "\n",
    "\n",
    "    mapping_key = cfg.var_col  # \"full_var_name\"\n",
    "\n",
    "    meta_cols = [cfg.unit_col, cfg.normal_min, cfg.normal_max]\n",
    "    meta_cols = [c for c in meta_cols if c in mapping_df.columns]\n",
    "\n",
    "    var_meta = (\n",
    "        mapping_df.drop_duplicates(subset=[mapping_key])\n",
    "                .set_index(mapping_key)[meta_cols]\n",
    "                .to_dict(orient=\"index\"))\n",
    "    \n",
    "    def render_variable_section(title: str, section_df: pd.DataFrame, var_list: list[str]) -> list[str]:\n",
    "        section_lines = [f\"# {title}\"]\n",
    "\n",
    "        for var_name in var_list:\n",
    "            # 1) metadata from MappingDF (unit + normal range)\n",
    "            meta = var_meta.get(var_name, {})\n",
    "            unit_str = meta.get(cfg.unit_col, \"\") if meta else \"\"\n",
    "            ref_min = meta.get(cfg.normal_min, None) if meta else None\n",
    "            ref_max = meta.get(cfg.normal_max, None) if meta else None\n",
    "\n",
    "            # 2) patient rows for this var (may be empty)\n",
    "            var_rows = section_df[section_df[cfg.var_col] == var_name]\n",
    "\n",
    "            section_lines.append(f\"- [{var_name}] ({unit_str})\\n\")\n",
    "            section_lines.append(\n",
    "                f\"\\t- Normal Value Range : {fmt_number(ref_min, cfg.round_ndigits, 'normal_min')} to {fmt_number(ref_max, cfg.round_ndigits, 'normal_max')}\"\n",
    "            )\n",
    "\n",
    "            # 3) if no observations -> keep unit/range, but stats/time are Not observed\n",
    "            n_valid = int(var_rows[cfg.val_col].notna().sum()) if not var_rows.empty else 0\n",
    "            if n_valid == 0:\n",
    "                section_lines.append(\"\\t- (Not observed)\")\n",
    "                continue\n",
    "\n",
    "            # 4) has observations -> compute features\n",
    "            feats = compute_variable_features(var_rows, cfg)\n",
    "            section_lines.append(\n",
    "                f\"\\t- First/Last Obs : {fmt_number(feats['first_min'], 0)} / {fmt_number(feats['last_min'], 0)}, \"\n",
    "                f\"N : {fmt_number(feats['n_obs'], 0)}, Interval : {fmt_number(feats['interval_mean_min'], 0)}\"\n",
    "            )\n",
    "\n",
    "            vs = feats[\"value_stats\"]\n",
    "            section_lines.append(\n",
    "                \"\\t- Statistics: \"\n",
    "                f\"[{fmt_number(vs['min'], cfg.round_ndigits)}, {fmt_number(vs['max'], cfg.round_ndigits)}, \"\n",
    "                f\"{fmt_number(vs['median'], cfg.round_ndigits)}, {fmt_number(vs['mean'], cfg.round_ndigits)}, \"\n",
    "                f\"{fmt_number(vs['std'], cfg.round_ndigits)}]\"\n",
    "            )\n",
    "            section_lines.append(\"\")\n",
    "\n",
    "        return section_lines\n",
    "\n",
    "\n",
    "    # def render_variable_section(title: str, section_df: pd.DataFrame, var_list : list = None) -> list[str]:\n",
    "    #     section_lines = [f\"# {title}\"]\n",
    "    #     section_lines.append(f\"## Time unit : minutes after admission, Obs : Observation Time, N : observation count, Interval : mean interval between observations, Statistics : [min, max, median, mean, std]\")\n",
    "\n",
    "    #     if section_df.empty:\n",
    "    #         section_lines.append(\"- (Not observed)\\n\")\n",
    "    #         return section_lines\n",
    "\n",
    "    #     for var_name, var_df in section_df.groupby(cfg.var_col):\n",
    "    #         # unit\n",
    "    #         unit_str = \"\"\n",
    "    #         if cfg.unit_col in var_df.columns and var_df[cfg.unit_col].notna().any():\n",
    "    #             unit_str = str(var_df[cfg.unit_col].dropna().iloc[0])\n",
    "\n",
    "    #         # normal range\n",
    "    #         ref_min, ref_max = var_df[cfg.normal_min].unique(), var_df[cfg.normal_max].unique()\n",
    "\n",
    "    #         # features\n",
    "    #         feats = compute_variable_features(var_df, cfg)\n",
    "\n",
    "    #         # (옵션) slope/variability level rule 넣고 싶으면 여기에 정의\n",
    "    #         slope_level = \"None\"\n",
    "    #         variability_level = \"None\"\n",
    "\n",
    "    #         section_lines.append(f\"- [{var_name}] ({unit_str})\\n\")\n",
    "    #         section_lines.append(\n",
    "    #             f\"\\t- Normal Value Range : {fmt_number(ref_min, cfg.round_ndigits)} to {fmt_number(ref_max, cfg.round_ndigits)}\"\n",
    "    #         )\n",
    "    #         section_lines.append(f\"\\t- First/Last Obs : {fmt_number(feats['first_min'], 0)} / {fmt_number(feats['last_min'], 0)},\" \\\n",
    "    #                              f\" N : {fmt_number(feats['n_obs'], 0)}, Interval : {fmt_number(feats['interval_mean_min'], 0)}\")\n",
    "\n",
    "    #         vs = feats[\"value_stats\"]\n",
    "    #         section_lines.append(\n",
    "    #             \"\\t- Statistics: \"\n",
    "    #             # f\"Min = {fmt_number(vs['min'], cfg.round_ndigits)}, \"\n",
    "    #             # f\"Max = {fmt_number(vs['max'], cfg.round_ndigits)}, \"\n",
    "    #             # f\"Median = {fmt_number(vs['median'], cfg.round_ndigits)}, \"\n",
    "    #             # f\"Mean = {fmt_number(vs['mean'], cfg.round_ndigits)}, \"\n",
    "    #             # f\"STD = {fmt_number(vs['std'], cfg.round_ndigits)}\"\n",
    "    #             f\"[{fmt_number(vs['min'], cfg.round_ndigits)}, {fmt_number(vs['max'], cfg.round_ndigits)}, {fmt_number(vs['median'], cfg.round_ndigits)}, {fmt_number(vs['mean'], cfg.round_ndigits)}, {fmt_number(vs['std'], cfg.round_ndigits)}]\"\n",
    "    #         )\n",
    "\n",
    "    #         # ss = feats[\"slope_stats\"]\n",
    "    #         # section_lines.append(\n",
    "    #         #     \"\\t- Statistics of Slopes : \"\n",
    "    #         #     f\"Min = {fmt_number(ss['min'], cfg.round_ndigits)} ({slope_level}), \"\n",
    "    #         #     f\"Max = {fmt_number(ss['max'], cfg.round_ndigits)} ({slope_level}), \"\n",
    "    #         #     f\"Mean = {fmt_number(ss['mean'], cfg.round_ndigits)} ({slope_level}), \"\n",
    "    #         #     f\"STD = {fmt_number(ss['std'], cfg.round_ndigits)}\"\n",
    "    #         # )\n",
    "\n",
    "    #         # vb = feats[\"variability_stats\"]\n",
    "    #         # section_lines.append(\n",
    "    #         #     \"\\t- Statistics of Variability : \"\n",
    "    #         #     f\"Min = {fmt_number(vb['min'], cfg.round_ndigits)} ({variability_level}), \"\n",
    "    #         #     f\"Max = {fmt_number(vb['max'], cfg.round_ndigits)} ({variability_level}), \"\n",
    "    #         #     f\"Mean = {fmt_number(vb['mean'], cfg.round_ndigits)} ({variability_level}), \"\n",
    "    #         #     f\"STD = {fmt_number(vb['std'], cfg.round_ndigits)}\"\n",
    "    #         # )\n",
    "    #         section_lines.append(\"\")  # blank line between vars\n",
    "\n",
    "    #     return section_lines\n",
    "\n",
    "    \n",
    "    md_lines.append(\"## Time unit : minutes after admission, Obs : Observation Time, N : observation count, \"\n",
    "            \"Interval : mean interval between observations, Statistics : [min, max, median, mean, std]\")\n",
    "    md_lines += render_variable_section(labs_title, labs_df, lab_var_list)\n",
    "    md_lines.append(\"\")  # spacer\n",
    "    md_lines += render_variable_section(\"Summary of Output Events\", output_df, ['Urine output'])\n",
    "\n",
    "    return \"\\n\".join(md_lines).strip()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Example Usage\n",
    "# ============================================================\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    cfg = MarkdownSummaryConfig(\n",
    "        time_col=\"charttime\",        # already minutes (int)\n",
    "        variability_mode=\"abs_delta\",\n",
    "        rolling_window=5,\n",
    "        round_ndigits=1\n",
    "    )\n",
    "\n",
    "    stay_ids = []\n",
    "    texts = []\n",
    "\n",
    "    for sid in tqdm(static_df.stay_id.unique()):\n",
    "        # change\n",
    "        patient_df = dynamics_df[(dynamics_df['stay_id'] == sid)]\n",
    "        patient_df = pd.merge(patient_df, MAPPING_DF, on = 'var_name', how = 'left')\n",
    "\n",
    "        demographics = static_df[static_df['stay_id'] == sid]\n",
    "        demographics = pd.merge(demographics, MAPPING_DF, on = 'var_name', how = 'left')\n",
    "\n",
    "\n",
    "        md_text = build_patient_markdown_summary(\n",
    "            observations=patient_df,\n",
    "            demographics=demographics,\n",
    "            mapping_df=MAPPING_DF,\n",
    "            cfg=cfg,\n",
    "            lab_var_list = lab_vars\n",
    "        )\n",
    "\n",
    "        stay_ids.append(sid)\n",
    "        texts.append(md_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a722eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.DataFrame(columns=['stay_id', 'text'])\n",
    "text_df['stay_id'] = stay_ids\n",
    "text_df['text'] = texts\n",
    "\n",
    "text_df.to_csv(HIRID_ROOT_DIR/'text_df.csv.gz', compression='gzip', index = False)\n",
    "\n",
    "# add length columns\n",
    "text_df['length'] = text_df['text'].apply(lambda x : len(x))\n",
    "\n",
    "max_length = text_df['length'].max()\n",
    "max_text = text_df[text_df['length'] == max_length]['text'].values[0]\n",
    "print(max_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c405ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"example.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(max_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cfc400b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Patient Demographics at ICU Admission\n",
      "\n",
      "- Age : 71.0\n",
      "- Gender : Male\n",
      "- Weight : 94.0kg\n",
      "- Height : 175.0cm \n",
      "\n",
      "\n",
      "## Time unit : minutes after admission, Obs : Observation Time, N : observation count, Interval : mean interval between observations, Statistics : [min, max, median, mean, std]\n",
      "# Summary of Lab Results\n",
      "- [Albumin] (g/dL)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to 6.0\n",
      "\t- First/Last Obs : 1333 / 1333, N : 1, Interval : Not observed\n",
      "\t- Statistics: [2.8, 2.8, 2.8, 2.8, 0.0]\n",
      "\n",
      "- [Alkaline phosphatase] (IU/L)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to inf\n",
      "\t- First/Last Obs : 1333 / 1333, N : 1, Interval : Not observed\n",
      "\t- Statistics: [37.0, 37.0, 37.0, 37.0, 0.0]\n",
      "\n",
      "- [Alanine aminotransferase] (IU/L)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to inf\n",
      "\t- First/Last Obs : 1333 / 1333, N : 1, Interval : Not observed\n",
      "\t- Statistics: [141.0, 141.0, 141.0, 141.0, 0.0]\n",
      "\n",
      "- [Aspartate aminotransferase] (IU/L)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to inf\n",
      "\t- First/Last Obs : 1333 / 1333, N : 1, Interval : Not observed\n",
      "\t- Statistics: [332.0, 332.0, 332.0, 332.0, 0.0]\n",
      "\n",
      "- [Base excess] (mmol/L)\n",
      "\n",
      "\t- Normal Value Range : -25.0 to 25.0\n",
      "\t- First/Last Obs : 235 / 235, N : 1, Interval : Not observed\n",
      "\t- Statistics: [2.0, 2.0, 2.0, 2.0, 0.0]\n",
      "\n",
      "- [Bicarbonate] (mmol/L)\n",
      "\n",
      "\t- Normal Value Range : 5.0 to 50.0\n",
      "\t- First/Last Obs : 235 / 1333, N : 12, Interval : 100\n",
      "\t- Statistics: [14.0, 25.3, 21.4, 20.7, 3.1]\n",
      "\n",
      "- [Bilirubin (total)] (mg/dL)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to 100.0\n",
      "\t- First/Last Obs : 1333 / 1333, N : 1, Interval : Not observed\n",
      "\t- Statistics: [3.3, 3.3, 3.3, 3.3, 0.0]\n",
      "\n",
      "- [Bilirubin (direct)] (mg/dL)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to 50.0\n",
      "\t- First/Last Obs : 1333 / 1333, N : 1, Interval : Not observed\n",
      "\t- Statistics: [2.2, 2.2, 2.2, 2.2, 0.0]\n",
      "\n",
      "- [Band form neutrophils] (%)\n",
      "\n",
      "\t- Normal Value Range : -inf to inf\n",
      "\t- (Not observed)\n",
      "- [Blood urea nitrogen] (mg/dL)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to 200.0\n",
      "\t- First/Last Obs : 1048 / 1333, N : 3, Interval : 142\n",
      "\t- Statistics: [27.0, 32.0, 31.0, 30.0, 2.6]\n",
      "\n",
      "- [Calcium] (mg/dL)\n",
      "\n",
      "\t- Normal Value Range : 4.0 to 20.0\n",
      "\t- First/Last Obs : 1048 / 1333, N : 3, Interval : 142\n",
      "\t- Statistics: [7.5, 8.1, 8.1, 7.9, 0.3]\n",
      "\n",
      "- [Calcium ionized] (mmol/L)\n",
      "\n",
      "\t- Normal Value Range : 0.5 to 2.0\n",
      "\t- First/Last Obs : 433 / 1408, N : 18, Interval : 57\n",
      "\t- Statistics: [0.7, 1.1, 1.0, 1.0, 0.1]\n",
      "\n",
      "- [Creatinine kinase] (IU/L)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to inf\n",
      "\t- First/Last Obs : 335 / 335, N : 1, Interval : Not observed\n",
      "\t- Statistics: [45.0, 45.0, 45.0, 45.0, 0.0]\n",
      "\n",
      "- [Creatinine kinase MB] (ng/mL)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to inf\n",
      "\t- First/Last Obs : 335 / 335, N : 1, Interval : Not observed\n",
      "\t- Statistics: [1.7, 1.7, 1.7, 1.7, 0.0]\n",
      "\n",
      "- [Chloride] (mmol/L)\n",
      "\n",
      "\t- Normal Value Range : 80.0 to 130.0\n",
      "\t- First/Last Obs : 434 / 1408, N : 11, Interval : 97\n",
      "\t- Statistics: [103.5, 110.0, 106.0, 106.6, 1.9]\n",
      "\n",
      "- [Creatinine] (mg/dL)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to 15.0\n",
      "\t- First/Last Obs : 1048 / 1333, N : 3, Interval : 142\n",
      "\t- Statistics: [1.8, 2.4, 2.1, 2.1, 0.3]\n",
      "\n",
      "- [C-reactive protein] (mg/L)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to inf\n",
      "\t- (Not observed)\n",
      "- [Fibrinogen] (mg/dL)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to 1500.0\n",
      "\t- First/Last Obs : 649 / 1048, N : 3, Interval : 200\n",
      "\t- Statistics: [393.0, 463.0, 425.0, 427.0, 35.0]\n",
      "\n",
      "- [Fraction of inspired oxygen] (%)\n",
      "\n",
      "\t- Normal Value Range : 21.0 to 100.0\n",
      "\t- First/Last Obs : 43 / 1423, N : 28, Interval : 115\n",
      "\t- Statistics: [60.0, 100.0, 90.0, 84.3, 17.5]\n",
      "\n",
      "- [Glucose] (mg/dL)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to 1000.0\n",
      "\t- First/Last Obs : 433 / 1408, N : 24, Interval : 42\n",
      "\t- Statistics: [151.0, 283.0, 211.8, 214.6, 33.1]\n",
      "\n",
      "- [Haemoglobin] (g/dL)\n",
      "\n",
      "\t- Normal Value Range : 4.0 to 18.0\n",
      "\t- First/Last Obs : 433 / 1408, N : 19, Interval : 54\n",
      "\t- Statistics: [6.3, 9.9, 7.5, 8.0, 1.0]\n",
      "\n",
      "- [International normalised ratio (INR)] ()\n",
      "\n",
      "\t- Normal Value Range : -inf to inf\n",
      "\t- First/Last Obs : 915 / 1333, N : 3, Interval : 209\n",
      "\t- Statistics: [2.2, 2.3, 2.3, 2.3, 0.1]\n",
      "\n",
      "- [Potassium] (mmol/L)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to 10.0\n",
      "\t- First/Last Obs : 433 / 1408, N : 19, Interval : 54\n",
      "\t- Statistics: [2.9, 5.1, 3.7, 3.6, 0.5]\n",
      "\n",
      "- [Lactate] (mmol/L)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to 50.0\n",
      "\t- First/Last Obs : 235 / 235, N : 1, Interval : Not observed\n",
      "\t- Statistics: [1.6, 1.6, 1.6, 1.6, 0.0]\n",
      "\n",
      "- [Lymphocytes] (%)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to 100.0\n",
      "\t- First/Last Obs : 1333 / 1333, N : 1, Interval : Not observed\n",
      "\t- Statistics: [6.0, 6.0, 6.0, 6.0, 0.0]\n",
      "\n",
      "- [Mean cell haemoglobin] (pg)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to inf\n",
      "\t- First/Last Obs : 1048 / 1333, N : 3, Interval : 142\n",
      "\t- Statistics: [26.7, 28.0, 27.8, 27.5, 0.7]\n",
      "\n",
      "- [Mean corpuscular haemoglobin concentration] (%)\n",
      "\n",
      "\t- Normal Value Range : 20.0 to 50.0\n",
      "\t- First/Last Obs : 1048 / 1333, N : 3, Interval : 142\n",
      "\t- Statistics: [32.1, 33.5, 32.7, 32.8, 0.7]\n",
      "\n",
      "- [Mean corpuscular volume] (fL)\n",
      "\n",
      "\t- Normal Value Range : 50.0 to 150.0\n",
      "\t- First/Last Obs : 1048 / 1333, N : 3, Interval : 142\n",
      "\t- Statistics: [83.0, 85.5, 83.1, 83.9, 1.4]\n",
      "\n",
      "- [Methaemoglobin] (%)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to 100.0\n",
      "\t- First/Last Obs : 434 / 1408, N : 11, Interval : 97\n",
      "\t- Statistics: [0.3, 1.2, 0.7, 0.7, 0.3]\n",
      "\n",
      "- [Magnesium] (mg/dL)\n",
      "\n",
      "\t- Normal Value Range : 0.5 to 5.0\n",
      "\t- First/Last Obs : 1333 / 1333, N : 1, Interval : Not observed\n",
      "\t- Statistics: [3.1, 3.1, 3.1, 3.1, 0.0]\n",
      "\n",
      "- [Sodium] (mmol/L)\n",
      "\n",
      "\t- Normal Value Range : 110.0 to 165.0\n",
      "\t- First/Last Obs : 433 / 1408, N : 19, Interval : 54\n",
      "\t- Statistics: [137.0, 153.5, 147.0, 146.1, 5.4]\n",
      "\n",
      "- [Neutrophils] (%)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to 100.0\n",
      "\t- First/Last Obs : 1333 / 1333, N : 1, Interval : Not observed\n",
      "\t- Statistics: [87.0, 87.0, 87.0, 87.0, 0.0]\n",
      "\n",
      "- [CO2 partial pressure] (mmHg)\n",
      "\n",
      "\t- Normal Value Range : 10.0 to 150.0\n",
      "\t- First/Last Obs : 235 / 1408, N : 20, Interval : 62\n",
      "\t- Statistics: [20.4, 54.9, 39.7, 40.5, 8.8]\n",
      "\n",
      "- [pH of blood] ()\n",
      "\n",
      "\t- Normal Value Range : 6.8 to 8.0\n",
      "\t- First/Last Obs : 235 / 1408, N : 20, Interval : 62\n",
      "\t- Statistics: [7.1, 7.6, 7.3, 7.3, 0.1]\n",
      "\n",
      "- [Phosphate] (mg/dL)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to 40.0\n",
      "\t- First/Last Obs : 1333 / 1333, N : 1, Interval : Not observed\n",
      "\t- Statistics: [4.6, 4.6, 4.6, 4.6, 0.0]\n",
      "\n",
      "- [Platelets] (1,000 / μL)\n",
      "\n",
      "\t- Normal Value Range : 5.0 to 1200.0\n",
      "\t- First/Last Obs : 649 / 1333, N : 5, Interval : 171\n",
      "\t- Statistics: [156.0, 259.0, 191.0, 201.6, 38.3]\n",
      "\n",
      "- [O2 partial pressure] (mmHg)\n",
      "\n",
      "\t- Normal Value Range : 40.0 to 600.0\n",
      "\t- First/Last Obs : 235 / 1408, N : 20, Interval : 62\n",
      "\t- Statistics: [64.3, 350.0, 143.5, 160.1, 81.9]\n",
      "\n",
      "- [Partial thromboplastin time] (sec)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to inf\n",
      "\t- First/Last Obs : 915 / 1048, N : 2, Interval : 133\n",
      "\t- Statistics: [98.0, 101.0, 99.5, 99.5, 2.1]\n",
      "\n",
      "- [Troponin T] (ng/mL)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to inf\n",
      "\t- First/Last Obs : 335 / 335, N : 1, Interval : Not observed\n",
      "\t- Statistics: [0.1, 0.1, 0.1, 0.1, 0.0]\n",
      "\n",
      "- [White blood cells] (1,000 / μL)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to inf\n",
      "\t- First/Last Obs : 1048 / 1333, N : 3, Interval : 142\n",
      "\t- Statistics: [17.5, 19.9, 17.7, 18.4, 1.3]\n",
      "\n",
      "\n",
      "# Summary of Output Events\n",
      "- [Urine output] (mL)\n",
      "\n",
      "\t- Normal Value Range : 0.0 to 2000.0\n",
      "\t- First/Last Obs : 43 / 1423, N : 14, Interval : 106\n",
      "\t- Statistics: [5.0, 600.0, 22.5, 72.9, 154.1]\n"
     ]
    }
   ],
   "source": [
    "with open(\"example.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b539cad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max text length 확인\n",
    "mimic_text = pd.read_csv(MIMIC_ROOT_DIR/'text_df.csv.gz', compression='gzip')\n",
    "eicu_text = pd.read_csv(EICU_ROOT_DIR/'text_df.csv.gz', compression='gzip')\n",
    "hirid_text = pd.read_csv(HIRID_ROOT_DIR/'text_df.csv.gz', compression='gzip')\n",
    "\n",
    "mimic_text['length'] = mimic_text['text'].apply(lambda x : len(x))\n",
    "eicu_text['length'] = eicu_text['text'].apply(lambda x : len(x))\n",
    "hirid_text['length'] = hirid_text['text'].apply(lambda x : len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41e9e190",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = mimic_text['length'].max()\n",
    "mimic_max_text = mimic_text[mimic_text['length'] == max_length]['text'].values[0]\n",
    "\n",
    "max_length = eicu_text['length'].max()\n",
    "eicu_max_text = eicu_text[eicu_text['length'] == max_length]['text'].values[0]\n",
    "\n",
    "max_length = hirid_text['length'].max()\n",
    "hirid_max_text = hirid_text[hirid_text['length'] == max_length]['text'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f674403",
   "metadata": {},
   "source": [
    "## Example for using LLaMA Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa4c6a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.39s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.1-8B\" \n",
    "\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5add4c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:03<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3258, 4096])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.1-8B\" \n",
    "\n",
    "config = AutoConfig.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# padding='max_length', max_length = 4800\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fd4dbb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3277, 4096])\n",
      "torch.Size([1, 3258, 4096])\n",
      "torch.Size([1, 3327, 4096])\n"
     ]
    }
   ],
   "source": [
    "# mimic\n",
    "mimic_inputs = tokenizer(mimic_max_text, truncation=True, return_tensors='pt')\n",
    "mimic_inputs['input_ids']\n",
    "\n",
    "# device로 이동\n",
    "mimic_inputs = {k: v.to(model.device) for k, v in mimic_inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    # input embedding table에서 바로 lookup\n",
    "    token_embeddings = model.get_input_embeddings()(mimic_inputs[\"input_ids\"])\n",
    "    # shape: [batch=1, seq_len, hidden_size]\n",
    "    print(token_embeddings.shape)\n",
    "\n",
    "# eicu\n",
    "eicu_inputs = tokenizer(eicu_max_text, truncation=True, return_tensors='pt')\n",
    "eicu_inputs['input_ids']\n",
    "\n",
    "# device로 이동\n",
    "eicu_inputs = {k: v.to(model.device) for k, v in eicu_inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    # input embedding table에서 바로 lookup\n",
    "    token_embeddings = model.get_input_embeddings()(eicu_inputs[\"input_ids\"])\n",
    "    # shape: [batch=1, seq_len, hidden_size]\n",
    "    print(token_embeddings.shape)\n",
    "\n",
    "# hirid\n",
    "hirid_inputs = tokenizer(hirid_max_text, truncation=True, return_tensors='pt')\n",
    "hirid_inputs['input_ids']\n",
    "\n",
    "# device로 이동\n",
    "hirid_inputs = {k: v.to(model.device) for k, v in hirid_inputs.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    # input embedding table에서 바로 lookup\n",
    "    token_embeddings = model.get_input_embeddings()(hirid_inputs[\"input_ids\"])\n",
    "    # shape: [batch=1, seq_len, hidden_size]\n",
    "    print(token_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dee3c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df5fe9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf07546",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c726c1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.41s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3327, 4096])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.1-8B\" \n",
    "\n",
    "TOKEN = 'your tokens'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id, use_auth_token=f\"{TOKEN}\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "enc = tokenizer(\n",
    "    max_text,\n",
    "    return_tensors=\"pt\",\n",
    "    truncation=True,\n",
    "    max_length=8192,   # 필요 시 조절\n",
    ")\n",
    "\n",
    "# device로 이동\n",
    "enc = {k: v.to(model.device) for k, v in enc.items()}\n",
    "\n",
    "with torch.no_grad():\n",
    "    # input embedding table에서 바로 lookup\n",
    "    token_embeddings = model.get_input_embeddings()(enc[\"input_ids\"])\n",
    "    # shape: [batch=1, seq_len, hidden_size]\n",
    "\n",
    "print(token_embeddings.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "603cc891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full length: 3326\n",
      "will be truncated to: 8192 ? False\n"
     ]
    }
   ],
   "source": [
    "full_ids = tokenizer(max_text, add_special_tokens=False).input_ids\n",
    "print(\"full length:\", len(full_ids))\n",
    "print(\"will be truncated to:\", 8192, \"?\", len(full_ids) > 8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90633bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0    128000  '<|begin_of_text|>'\n",
      "   1         2  '#'\n",
      "   2     30024  'ĠPatient'\n",
      "   3      4829  'ĠDem'\n",
      "   4     45245  'ographics'\n",
      "   5       520  'Ġat'\n",
      "   6     85015  'ĠICU'\n",
      "   7     63446  'ĠAdmission'\n",
      "   8       271  'ĊĊ'\n",
      "   9        12  '-'\n",
      "  10     13381  'ĠAge'\n",
      "  11       551  'Ġ:'\n",
      "  12       220  'Ġ'\n",
      "  13      2031  '70'\n",
      "  14        13  '.'\n",
      "  15       931  '000'\n",
      "  16       198  'Ċ'\n",
      "  17        12  '-'\n",
      "  18     29317  'ĠGender'\n",
      "  19       551  'Ġ:'\n",
      "  20       435  'ĠF'\n",
      "  21       198  'Ċ'\n",
      "  22        12  '-'\n",
      "  23     16923  'ĠWeight'\n",
      "  24       551  'Ġ:'\n",
      "  25       220  'Ġ'\n",
      "  26      1399  '60'\n",
      "  27        13  '.'\n",
      "  28       931  '000'\n",
      "  29      7501  'kg'\n",
      "  30       198  'Ċ'\n",
      "  31        12  '-'\n",
      "  32     22147  'ĠHeight'\n",
      "  33       551  'Ġ:'\n",
      "  34       220  'Ġ'\n",
      "  35      8258  '170'\n",
      "  36        13  '.'\n",
      "  37       931  '000'\n",
      "  38      6358  'cm'\n",
      "  39     15073  'ĠĊĊĊ'\n",
      "  40       567  '##'\n",
      "  41      4212  'ĠTime'\n",
      "  42      5089  'Ġunit'\n",
      "  43       551  'Ġ:'\n",
      "  44      4520  'Ġminutes'\n",
      "  45      1306  'Ġafter'\n",
      "  46     26360  'Ġadmission'\n",
      "  47        11  ','\n",
      "  48     51541  'ĠObs'\n",
      "  49       551  'Ġ:'\n",
      "  50     87529  'ĠObservation'\n",
      "  51      4212  'ĠTime'\n",
      "  52        11  ','\n",
      "  53       452  'ĠN'\n",
      "  54       551  'Ġ:'\n",
      "  55     22695  'Ġobservation'\n",
      "  56      1797  'Ġcount'\n",
      "  57        11  ','\n",
      "  58     41684  'ĠInterval'\n",
      "  59       551  'Ġ:'\n",
      "  60      3152  'Ġmean'\n",
      "  61     10074  'Ġinterval'\n",
      "  62      1990  'Ġbetween'\n",
      "  63     24654  'Ġobservations'\n",
      "  64        11  ','\n",
      "  65     25647  'ĠStatistics'\n",
      "  66       551  'Ġ:'\n",
      "  67       510  'Ġ['\n",
      "  68      1083  'min'\n",
      "  69        11  ','\n",
      "  70      1973  'Ġmax'\n",
      "  71        11  ','\n",
      "  72     23369  'Ġmedian'\n",
      "  73        11  ','\n",
      "  74      3152  'Ġmean'\n",
      "  75        11  ','\n",
      "  76      1487  'Ġstd'\n",
      "  77       933  ']Ċ'\n",
      "  78         2  '#'\n",
      "  79     22241  'ĠSummary'\n",
      "  80       315  'Ġof'\n",
      "  81     11868  'ĠLab'\n",
      "  82     18591  'ĠResults'\n",
      "  83       198  'Ċ'\n",
      "  84        12  '-'\n",
      "  85       510  'Ġ['\n",
      "  86     33478  'Album'\n",
      "  87       258  'in'\n",
      "  88        60  ']'\n",
      "  89       320  'Ġ('\n",
      "  90        70  'g'\n",
      "  91      3529  '/d'\n",
      "  92        43  'L'\n",
      "  93       696  ')ĊĊ'\n",
      "  94       197  'ĉ'\n",
      "  95        12  '-'\n",
      "  96     18944  'ĠNormal'\n",
      "  97      5273  'ĠValue'\n",
      "  98     16842  'ĠRange'\n",
      "  99       551  'Ġ:'\n",
      " 100       220  'Ġ'\n",
      " 101        15  '0'\n",
      " 102        13  '.'\n",
      " 103       931  '000'\n",
      " 104       311  'Ġto'\n",
      " 105       220  'Ġ'\n",
      " 106        21  '6'\n",
      " 107        13  '.'\n",
      " 108       931  '000'\n",
      " 109       198  'Ċ'\n",
      " 110       197  'ĉ'\n",
      " 111        12  '-'\n",
      " 112       320  'Ġ('\n",
      " 113      2688  'Not'\n",
      " 114     13468  'Ġobserved'\n",
      " 115       340  ')Ċ'\n",
      " 116        12  '-'\n",
      " 117       510  'Ġ['\n",
      " 118      2149  'Al'\n",
      " 119     36641  'kal'\n",
      " 120       483  'ine'\n",
      " 121     33088  'Ġphosph'\n",
      " 122       266  'at'\n",
      " 123       521  'ase'\n",
      " 124        60  ']'\n",
      " 125       320  'Ġ('\n",
      " 126     81100  'IU'\n",
      " 127      7586  '/L'\n",
      " 128       696  ')ĊĊ'\n",
      " 129       197  'ĉ'\n",
      " 130        12  '-'\n",
      " 131     18944  'ĠNormal'\n",
      " 132      5273  'ĠValue'\n",
      " 133     16842  'ĠRange'\n",
      " 134       551  'Ġ:'\n",
      " 135       220  'Ġ'\n",
      " 136        15  '0'\n",
      " 137        13  '.'\n",
      " 138       931  '000'\n",
      " 139       311  'Ġto'\n",
      " 140      4225  'Ġinf'\n",
      " 141       198  'Ċ'\n",
      " 142       197  'ĉ'\n",
      " 143        12  '-'\n",
      " 144      5629  'ĠFirst'\n",
      " 145        14  '/'\n",
      " 146      5966  'Last'\n",
      " 147     51541  'ĠObs'\n",
      " 148       551  'Ġ:'\n",
      " 149       220  'Ġ'\n",
      " 150      2131  '55'\n",
      " 151       611  'Ġ/'\n",
      " 152       220  'Ġ'\n",
      " 153      2131  '55'\n",
      " 154        11  ','\n",
      " 155       452  'ĠN'\n",
      " 156       551  'Ġ:'\n",
      " 157       220  'Ġ'\n",
      " 158        16  '1'\n",
      " 159        11  ','\n",
      " 160     41684  'ĠInterval'\n",
      " 161       551  'Ġ:'\n",
      " 162      2876  'ĠNot'\n",
      " 163     13468  'Ġobserved'\n",
      " 164       198  'Ċ'\n",
      " 165       197  'ĉ'\n",
      " 166        12  '-'\n",
      " 167     25647  'ĠStatistics'\n",
      " 168        25  ':'\n",
      " 169       510  'Ġ['\n",
      " 170      4767  '76'\n",
      " 171        13  '.'\n",
      " 172       931  '000'\n",
      " 173        11  ','\n",
      " 174       220  'Ġ'\n",
      " 175      4767  '76'\n",
      " 176        13  '.'\n",
      " 177       931  '000'\n",
      " 178        11  ','\n",
      " 179       220  'Ġ'\n",
      " 180      4767  '76'\n",
      " 181        13  '.'\n",
      " 182       931  '000'\n",
      " 183        11  ','\n",
      " 184       220  'Ġ'\n",
      " 185      4767  '76'\n",
      " 186        13  '.'\n",
      " 187       931  '000'\n",
      " 188        11  ','\n",
      " 189       220  'Ġ'\n",
      " 190        15  '0'\n",
      " 191        13  '.'\n",
      " 192       931  '000'\n",
      " 193      2595  ']ĊĊ'\n",
      " 194        12  '-'\n",
      " 195       510  'Ġ['\n",
      " 196     68724  'Alan'\n",
      " 197       483  'ine'\n",
      " 198       264  'Ġa'\n",
      " 199      1083  'min'\n"
     ]
    }
   ],
   "source": [
    "enc = tokenizer(\n",
    "    md_text,\n",
    "    return_tensors=\"pt\",\n",
    "    max_length=4096,\n",
    "    return_overflowing_tokens=False,\n",
    ")\n",
    "\n",
    "ids = enc[\"input_ids\"][0].tolist()                 # [seq_len]\n",
    "tokens = tokenizer.convert_ids_to_tokens(ids)      # 토큰 문자열(대부분 BPE 조각)\n",
    "\n",
    "for i, (tid, tok) in enumerate(zip(ids[:200], tokens[:200])):  # 앞 200개만 예시\n",
    "    print(f\"{i:4d}  {tid:8d}  {repr(tok)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
